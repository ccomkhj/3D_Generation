{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import logging\n",
    "import open3d as o3d\n",
    "\n",
    "\n",
    "class View:\n",
    "    \"\"\"Represents an image used in the reconstruction\"\"\"\n",
    "\n",
    "    def __init__(self, image_path, root_path, feature_path, feature_type='sift'):\n",
    "\n",
    "        self.name = image_path[image_path.rfind('/') + 1:-4]  # image name without extension\n",
    "        self.image = cv2.imread(image_path)  # numpy array of the image\n",
    "        self.keypoints = []  # list of keypoints obtained from feature extraction\n",
    "        self.descriptors = []  # list of descriptors obtained from feature extraction\n",
    "        self.feature_type = feature_type  # feature extraction method\n",
    "        self.root_path = root_path  # root directory containing the image folder\n",
    "        self.R = np.zeros((3, 3), dtype=float)  # rotation matrix for the view\n",
    "        self.t = np.zeros((3, 1), dtype=float)  # translation vector for the view\n",
    "\n",
    "        if not feature_path:\n",
    "            self.extract_features()\n",
    "        else:\n",
    "            self.read_features()\n",
    "\n",
    "    def extract_features(self):\n",
    "        \"\"\"Extracts features from the image\"\"\"\n",
    "\n",
    "        if self.feature_type == 'sift':\n",
    "            detector = cv2.xfeatures2d.SIFT_create()\n",
    "        elif self.feature_type == 'surf':\n",
    "            detector = cv2.xfeatures2d.SURF_create()\n",
    "        elif self.feature_type == 'orb':\n",
    "            detector = cv2.ORB_create(nfeatures=1500)\n",
    "        else:\n",
    "            logging.error(\"Admitted feature types are SIFT, SURF or ORB\")\n",
    "            sys.exit(0)\n",
    "\n",
    "        self.keypoints, self.descriptors = detector.detectAndCompute(self.image, None)\n",
    "        logging.info(\"Computed features for image %s\", self.name)\n",
    "\n",
    "        self.write_features()\n",
    "\n",
    "    def read_features(self):\n",
    "        \"\"\"Reads features stored in files. Feature files have filenames corresponding to image names without extensions\"\"\"\n",
    "\n",
    "        # logic to compute features for images that don't have pkl files\n",
    "        try:\n",
    "            features = pickle.load(open(os.path.join(self.root_path, 'features', self.name + '.pkl'), \"rb\"))\n",
    "            logging.info(\"Read features from file for image %s\", self.name)\n",
    "\n",
    "            keypoints = []\n",
    "            descriptors = []\n",
    "\n",
    "            for point in features:\n",
    "                keypoint = cv2.KeyPoint(x=point[0][0], y=point[0][1], _size=point[1], _angle=point[2],\n",
    "                                        _response=point[3], _octave=point[4], _class_id=point[5])\n",
    "                descriptor = point[6]\n",
    "                keypoints.append(keypoint)\n",
    "                descriptors.append(descriptor)\n",
    "\n",
    "            self.keypoints = keypoints\n",
    "            self.descriptors = np.array(descriptors)  # convert descriptors into n x 128 numpy array\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            logging.error(\"Pkl file not found for image %s. Computing from scratch\", self.name)\n",
    "            self.extract_features()\n",
    "\n",
    "    def write_features(self):\n",
    "        \"\"\"Stores computed features to pkl files. The files are written inside a features directory inside the root directory\"\"\"\n",
    "\n",
    "        if not os.path.exists(os.path.join(self.root_path, 'features')):\n",
    "            os.makedirs(os.path.join(self.root_path, 'features'))\n",
    "\n",
    "        temp_array = []\n",
    "        for idx, point in enumerate(self.keypoints):\n",
    "            temp = (point.pt, point.size, point.angle, point.response, point.octave, point.class_id,\n",
    "                    self.descriptors[idx])\n",
    "            temp_array.append(temp)\n",
    "\n",
    "        features_file = open(os.path.join(self.root_path, 'features', self.name + '.pkl'), 'wb')\n",
    "        pickle.dump(temp_array, features_file)\n",
    "        features_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'images/box_simple'\n",
    "image_fotmat = 'jpg'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Created features directory\n",
      "INFO:root:Computing features\n",
      "ERROR:root:Pkl file not found for image 1_left. Computing from scratch\n",
      "INFO:root:Computed features for image 1_left\n",
      "ERROR:root:Pkl file not found for image 2_center. Computing from scratch\n",
      "INFO:root:Computed features for image 2_center\n",
      "ERROR:root:Pkl file not found for image 3_right. Computing from scratch\n",
      "INFO:root:Computed features for image 3_right\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Loops through the images and creates an array of views\"\"\"\n",
    "\n",
    "feature_path = False\n",
    "\n",
    "# if features directory exists, the feature files are read from there\n",
    "logging.info(\"Created features directory\")\n",
    "if os.path.exists(os.path.join(image_path, 'features')):\n",
    "    feature_path = True\n",
    "\n",
    "image_names = sorted(glob.glob(os.path.join(image_path, '*.' + image_fotmat)))\n",
    "\n",
    "logging.info(\"Computing features\")\n",
    "views = []\n",
    "for image_name in image_names:\n",
    "    views.append(View(image_name, image_path, feature_path=feature_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Match:\n",
    "    \"\"\"Represents a feature matches between two views\"\"\"\n",
    "\n",
    "    def __init__(self, view1, view2, match_path):\n",
    "\n",
    "        self.indices1 = []  # indices of the matched keypoints in the first view\n",
    "        self.indices2 = []  # indices of the matched keypoints in the second view\n",
    "        self.distances = []  # distance between the matched keypoints in the first view\n",
    "        self.image_name1 = view1.name  # name of the first view\n",
    "        self.image_name2 = view2.name  # name of the second view\n",
    "        self.root_path = view1.root_path  # root directory containing the image folder\n",
    "        self.inliers1 = []  # list to store the indices of the keypoints from the first view not removed using the fundamental matrix\n",
    "        self.inliers2 = []  # list to store the indices of the keypoints from the second view not removed using the fundamental matrix\n",
    "        self.view1 = view1\n",
    "        self.view2 = view2\n",
    "\n",
    "        if view1.feature_type in ['sift', 'surf']:\n",
    "            self.matcher = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
    "        else:\n",
    "            self.matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "        if not match_path:\n",
    "            self.get_matches(view1, view2)\n",
    "        else:\n",
    "            self.read_matches()\n",
    "\n",
    "    def get_matches(self, view1, view2):\n",
    "        \"\"\"Extracts feature matches between two views\"\"\"\n",
    "\n",
    "        matches = self.matcher.match(view1.descriptors, view2.descriptors)\n",
    "        matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "        # store match components in their respective lists\n",
    "        for i in range(len(matches)):\n",
    "            self.indices1.append(matches[i].queryIdx)\n",
    "            self.indices2.append(matches[i].trainIdx)\n",
    "            self.distances.append(matches[i].distance)\n",
    "\n",
    "        logging.info(\"Computed matches between view %s and view %s\", self.image_name1, self.image_name2)\n",
    "\n",
    "        self.write_matches()\n",
    "\n",
    "    def write_matches(self):\n",
    "        \"\"\"Writes a match to a pkl file in the root_path/matches directory\"\"\"\n",
    "\n",
    "        if not os.path.exists(os.path.join(self.root_path, 'matches')):\n",
    "            os.makedirs(os.path.join(self.root_path, 'matches'))\n",
    "\n",
    "        temp_array = []\n",
    "        for i in range(len(self.indices1)):\n",
    "            temp = (self.distances[i], self.indices1[i], self.indices2[i])\n",
    "            temp_array.append(temp)\n",
    "\n",
    "        matches_file = open(os.path.join(self.root_path, 'matches', self.image_name1 + '_' + self.image_name2 + '.pkl'), 'wb')\n",
    "        pickle.dump(temp_array, matches_file)\n",
    "        matches_file.close()\n",
    "\n",
    "    def read_matches(self):\n",
    "        \"\"\"Reads matches from file\"\"\"\n",
    "\n",
    "        try:\n",
    "            matches = pickle.load(\n",
    "                open(\n",
    "                    os.path.join(self.root_path, 'matches', self.image_name1 + '_' + self.image_name2 + '.pkl'),\n",
    "                    \"rb\"\n",
    "                )\n",
    "            )\n",
    "            logging.info(\"Read matches from file for view pair pair %s %s\", self.image_name1, self.image_name2)\n",
    "\n",
    "            for point in matches:\n",
    "                self.distances.append(point[0])\n",
    "                self.indices1.append(point[1])\n",
    "                self.indices2.append(point[2])\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            logging.error(\"Pkl file not found for match %s_%s. Computing from scratch\", self.image_name1, self.image_name2)\n",
    "            self.get_matches(self.view1, self.view2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Computed matches between view 1_left and view 2_center\n",
      "INFO:root:Computed matches between view 1_left and view 3_right\n",
      "INFO:root:Computed matches between view 2_center and view 3_right\n"
     ]
    }
   ],
   "source": [
    "match_path = False\n",
    "\n",
    "root_path = views[0].root_path\n",
    "\n",
    "if os.path.exists(os.path.join(root_path, 'matches')):\n",
    "    match_path = True\n",
    "\n",
    "matches = {}\n",
    "for i in range(0, len(views) - 1):\n",
    "    for j in range(i+1, len(views)):\n",
    "        matches[(views[i].name, views[j].name)] = Match(views[i], views[j], match_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intrinsic Parameter of my phone camera.\n",
    "It is computed using a checker board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = np.array([[3.17806911e+03, 0.00000000e+00, 2.05870863e+03],\n",
    "       [0.00000000e+00, 3.20224083e+03, 1.45232682e+03],\n",
    "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Util functions to compute Sfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_keypoints_from_indices(keypoints1, index_list1, keypoints2, index_list2):\n",
    "    \"\"\"Filters a list of keypoints based on the indices given\"\"\"\n",
    "\n",
    "    points1 = np.array([kp.pt for kp in keypoints1])[index_list1]\n",
    "    points2 = np.array([kp.pt for kp in keypoints2])[index_list2]\n",
    "    return points1, points2\n",
    "\n",
    "\n",
    "def get_3D_point(u1, P1, u2, P2):\n",
    "    \"\"\"Solves for 3D point using homogeneous 2D points and the respective camera matrices\"\"\"\n",
    "\n",
    "    A = np.array([[u1[0] * P1[2, 0] - P1[0, 0], u1[0] * P1[2, 1] - P1[0, 1], u1[0] * P1[2, 2] - P1[0, 2]],\n",
    "                  [u1[1] * P1[2, 0] - P1[1, 0], u1[1] * P1[2, 1] - P1[1, 1], u1[1] * P1[2, 2] - P1[1, 2]],\n",
    "                  [u2[0] * P2[2, 0] - P2[0, 0], u2[0] * P2[2, 1] - P2[0, 1], u2[0] * P2[2, 2] - P2[0, 2]],\n",
    "                  [u2[1] * P2[2, 0] - P2[1, 0], u2[1] * P2[2, 1] - P2[1, 1], u2[1] * P2[2, 2] - P2[1, 2]]])\n",
    "\n",
    "    B = np.array([-(u1[0] * P1[2, 3] - P1[0, 3]),\n",
    "                  -(u1[1] * P1[2, 3] - P1[1, 3]),\n",
    "                  -(u2[0] * P2[2, 3] - P2[0, 3]),\n",
    "                  -(u2[1] * P2[2, 3] - P2[1, 3])])\n",
    "\n",
    "    X = cv2.solve(A, B, flags=cv2.DECOMP_SVD)\n",
    "    return X[1]\n",
    "\n",
    "\n",
    "def remove_outliers_using_F(view1, view2, match_object):\n",
    "    \"\"\"Removes outlier keypoints using the fundamental matrix\"\"\"\n",
    "\n",
    "    pixel_points1, pixel_points2 = get_keypoints_from_indices(keypoints1=view1.keypoints,\n",
    "                                                              keypoints2=view2.keypoints,\n",
    "                                                              index_list1=match_object.indices1,\n",
    "                                                              index_list2=match_object.indices2)\n",
    "    F, mask = cv2.findFundamentalMat(pixel_points1, pixel_points2, method=cv2.FM_RANSAC,\n",
    "                                     ransacReprojThreshold=0.9, confidence=0.99)\n",
    "    mask = mask.astype(bool).flatten()\n",
    "    match_object.inliers1 = np.array(match_object.indices1)[mask]\n",
    "    match_object.inliers2 = np.array(match_object.indices2)[mask]\n",
    "\n",
    "    return F\n",
    "\n",
    "\n",
    "def calculate_reprojection_error(point_3D, point_2D, K, R, t):\n",
    "    \"\"\"Calculates the reprojection error for a 3D point by projecting it back into the image plane\"\"\"\n",
    "\n",
    "    reprojected_point = K.dot(R.dot(point_3D) + t)\n",
    "    reprojected_point = cv2.convertPointsFromHomogeneous(reprojected_point.T)[:, 0, :].T\n",
    "    error = np.linalg.norm(point_2D.reshape((2, 1)) - reprojected_point)\n",
    "    return error\n",
    "\n",
    "\n",
    "def get_camera_from_E(E):\n",
    "    \"\"\"Calculates rotation and translation component from essential matrix\"\"\"\n",
    "\n",
    "    W = np.array([[0, -1, 0], [1, 0, 0], [0, 0, 1]])\n",
    "    W_t = W.T\n",
    "    u, w, vt = np.linalg.svd(E)\n",
    "\n",
    "    R1 = u @ W @ vt\n",
    "    R2 = u @ W_t @ vt\n",
    "    t1 = u[:, -1].reshape((3, 1))\n",
    "    t2 = - t1\n",
    "    return R1, R2, t1, t2\n",
    "\n",
    "\n",
    "def check_determinant(R):\n",
    "    \"\"\"Validates using the determinant of the rotation matrix\"\"\"\n",
    "\n",
    "    if np.linalg.det(R) + 1.0 < 1e-9:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "\n",
    "def check_triangulation(points, P):\n",
    "    \"\"\"Checks whether reconstructed points lie in front of the camera\"\"\"\n",
    "\n",
    "    P = np.vstack((P, np.array([0, 0, 0, 1])))\n",
    "    reprojected_points = cv2.perspectiveTransform(src=points[np.newaxis], m=P)\n",
    "    z = reprojected_points[0, :, -1]\n",
    "    if (np.sum(z > 0)/z.shape[0]) < 0.75:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Baseline:\n",
    "    \"\"\"Represents the functions that compute the baseline pose from the initial images of a reconstruction\"\"\"\n",
    "\n",
    "    def __init__(self, view1, view2, match_object):\n",
    "\n",
    "        self.view1 = view1  # first view\n",
    "        self.view1.R = np.eye(3, 3)  # identity rotation since the first view is said to be at the origin\n",
    "        self.view2 = view2  # second view\n",
    "        self.match_object = match_object  # match object between first and second view\n",
    "\n",
    "    def get_pose(self, K):\n",
    "        \"\"\"Computes and returns the rotation and translation components for the second view\"\"\"\n",
    "\n",
    "        F = remove_outliers_using_F(self.view1, self.view2, self.match_object)\n",
    "        E = K.T @ F @ K  # compute the essential matrix from the fundamental matrix\n",
    "        logging.info(\"Computed essential matrix\")\n",
    "        logging.info(\"Choosing correct pose out of 4 solutions\")\n",
    "\n",
    "        return self.check_pose(E, K)\n",
    "\n",
    "    def check_pose(self, E, K):\n",
    "        \"\"\"Retrieves the rotation and translation components from the essential matrix by decomposing it and verifying the validity of the 4 possible solutions\"\"\"\n",
    "\n",
    "        R1, R2, t1, t2 = get_camera_from_E(E)  # decompose E\n",
    "        if not check_determinant(R1):\n",
    "            R1, R2, t1, t2 = get_camera_from_E(-E)  # change sign of E if R1 fails the determinant test\n",
    "\n",
    "        # solution 1\n",
    "        reprojection_error, points_3D = self.triangulate(K, R1, t1)\n",
    "        # check if reprojection is not faulty and if the points are correctly triangulated in the front of the camera\n",
    "        if reprojection_error > 100.0 or not check_triangulation(points_3D, np.hstack((R1, t1))):\n",
    "\n",
    "            # solution 2\n",
    "            reprojection_error, points_3D = self.triangulate(K, R1, t2)\n",
    "            if reprojection_error > 100.0 or not check_triangulation(points_3D, np.hstack((R1, t2))):\n",
    "\n",
    "                # solution 3\n",
    "                reprojection_error, points_3D = self.triangulate(K, R2, t1)\n",
    "                if reprojection_error > 100.0 or not check_triangulation(points_3D, np.hstack((R2, t1))):\n",
    "\n",
    "                    # solution 4\n",
    "                    return R2, t2\n",
    "\n",
    "                else:\n",
    "                    return R2, t1\n",
    "\n",
    "            else:\n",
    "                return R1, t2\n",
    "\n",
    "        else:\n",
    "            return R1, t1\n",
    "\n",
    "    def triangulate(self, K, R, t):\n",
    "        \"\"\"Triangulate points between the baseline views and calculates the mean reprojection error of the triangulation\"\"\"\n",
    "\n",
    "        K_inv = np.linalg.inv(K)\n",
    "        P1 = np.hstack((self.view1.R, self.view1.t))\n",
    "        P2 = np.hstack((R, t))\n",
    "\n",
    "        # only reconstructs the inlier points filtered using the fundamental matrix\n",
    "        pixel_points1, pixel_points2 = get_keypoints_from_indices(keypoints1=self.view1.keypoints,\n",
    "                                                                  keypoints2=self.view2.keypoints,\n",
    "                                                                  index_list1=self.match_object.inliers1,\n",
    "                                                                  index_list2=self.match_object.inliers2)\n",
    "\n",
    "        # convert 2D pixel points to homogeneous coordinates\n",
    "        pixel_points1 = cv2.convertPointsToHomogeneous(pixel_points1)[:, 0, :]\n",
    "        pixel_points2 = cv2.convertPointsToHomogeneous(pixel_points2)[:, 0, :]\n",
    "\n",
    "        reprojection_error = []\n",
    "\n",
    "        points_3D = np.zeros((0, 3))  # stores the triangulated points\n",
    "\n",
    "        for i in range(len(pixel_points1)):\n",
    "            u1 = pixel_points1[i, :]\n",
    "            u2 = pixel_points2[i, :]\n",
    "\n",
    "            # convert homogeneous 2D points to normalized device coordinates\n",
    "            u1_normalized = K_inv.dot(u1)\n",
    "            u2_normalized = K_inv.dot(u2)\n",
    "\n",
    "            # calculate 3D point\n",
    "            point_3D = get_3D_point(u1_normalized, P1, u2_normalized, P2)\n",
    "\n",
    "            # calculate reprojection error\n",
    "            error = calculate_reprojection_error(point_3D, u2[0:2], K, R, t)\n",
    "            reprojection_error.append(error)\n",
    "\n",
    "            # append point\n",
    "            points_3D = np.concatenate((points_3D, point_3D.T), axis=0)\n",
    "\n",
    "        return np.mean(reprojection_error), points_3D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SFM:\n",
    "    \"\"\"Represents the main reconstruction loop\"\"\"\n",
    "\n",
    "    def __init__(self, views, matches, K):\n",
    "\n",
    "        self.views = views  # list of views\n",
    "        self.matches = matches  # dictionary of matches\n",
    "        self.names = []  # image names\n",
    "        self.done = []  # list of views that have been reconstructed\n",
    "        self.K = K  # intrinsic matrix\n",
    "        self.points_3D = np.zeros((0, 3))  # reconstructed 3D points\n",
    "        self.point_counter = 0  # keeps track of the reconstructed points\n",
    "        self.point_map = {}  # a dictionary of the 2D points that contributed to a given 3D point\n",
    "        self.errors = []  # list of mean reprojection errors taken at the end of every new view being added\n",
    "\n",
    "        for view in self.views:\n",
    "            self.names.append(view.name)\n",
    "\n",
    "        if not os.path.exists(self.views[0].root_path + '/points'):\n",
    "            os.makedirs(self.views[0].root_path + '/points')\n",
    "\n",
    "        # store results in a root_path/points\n",
    "        self.results_path = os.path.join(self.views[0].root_path, 'points')\n",
    "\n",
    "    def get_index_of_view(self, view):\n",
    "        \"\"\"Extracts the position of a view in the list of views\"\"\"\n",
    "\n",
    "        return self.names.index(view.name)\n",
    "\n",
    "    def remove_mapped_points(self, match_object, image_idx):\n",
    "        \"\"\"Removes points that have already been reconstructed in the completed views\"\"\"\n",
    "\n",
    "        inliers1 = []\n",
    "        inliers2 = []\n",
    "\n",
    "        for i in range(len(match_object.inliers1)):\n",
    "            if (image_idx, match_object.inliers1[i]) not in self.point_map:\n",
    "                inliers1.append(match_object.inliers1[i])\n",
    "                inliers2.append(match_object.inliers2[i])\n",
    "\n",
    "        match_object.inliers1 = inliers1\n",
    "        match_object.inliers2 = inliers2\n",
    "\n",
    "    def compute_pose(self, view1, view2=None, is_baseline=False):\n",
    "        \"\"\"Computes the pose of the new view\"\"\"\n",
    "\n",
    "        # procedure for baseline pose estimation\n",
    "        if is_baseline and view2:\n",
    "\n",
    "            match_object = self.matches[(view1.name, view2.name)]\n",
    "            baseline_pose = Baseline(view1, view2, match_object)\n",
    "            view2.R, view2.t = baseline_pose.get_pose(self.K)\n",
    "\n",
    "            rpe1, rpe2 = self.triangulate(view1, view2)\n",
    "            self.errors.append(np.mean(rpe1))\n",
    "            self.errors.append(np.mean(rpe2))\n",
    "\n",
    "            self.done.append(view1)\n",
    "            self.done.append(view2)\n",
    "\n",
    "        # procedure for estimating the pose of all other views\n",
    "        else:\n",
    "\n",
    "            view1.R, view1.t = self.compute_pose_PNP(view1)\n",
    "            errors = []\n",
    "\n",
    "            # reconstruct unreconstructed points from all of the previous views\n",
    "            for i, old_view in enumerate(self.done):\n",
    "\n",
    "                match_object = self.matches[(old_view.name, view1.name)]\n",
    "                _ = remove_outliers_using_F(old_view, view1, match_object)\n",
    "                self.remove_mapped_points(match_object, i)\n",
    "                _, rpe = self.triangulate(old_view, view1)\n",
    "                errors += rpe\n",
    "\n",
    "            self.done.append(view1)\n",
    "            self.errors.append(np.mean(errors))\n",
    "\n",
    "    def triangulate(self, view1, view2):\n",
    "        \"\"\"Triangulates 3D points from two views whose poses have been recovered. Also updates the point_map dictionary\"\"\"\n",
    "\n",
    "        K_inv = np.linalg.inv(self.K)\n",
    "        P1 = np.hstack((view1.R, view1.t))\n",
    "        P2 = np.hstack((view2.R, view2.t))\n",
    "\n",
    "        match_object = self.matches[(view1.name, view2.name)]\n",
    "        pixel_points1, pixel_points2 = get_keypoints_from_indices(keypoints1=view1.keypoints,\n",
    "                                                                  keypoints2=view2.keypoints,\n",
    "                                                                  index_list1=match_object.inliers1,\n",
    "                                                                  index_list2=match_object.inliers2)\n",
    "        pixel_points1 = cv2.convertPointsToHomogeneous(pixel_points1)[:, 0, :]\n",
    "        pixel_points2 = cv2.convertPointsToHomogeneous(pixel_points2)[:, 0, :]\n",
    "        reprojection_error1 = []\n",
    "        reprojection_error2 = []\n",
    "\n",
    "        for i in range(len(pixel_points1)):\n",
    "\n",
    "            u1 = pixel_points1[i, :]\n",
    "            u2 = pixel_points2[i, :]\n",
    "\n",
    "            u1_normalized = K_inv.dot(u1)\n",
    "            u2_normalized = K_inv.dot(u2)\n",
    "\n",
    "            point_3D = get_3D_point(u1_normalized, P1, u2_normalized, P2)\n",
    "            self.points_3D = np.concatenate((self.points_3D, point_3D.T), axis=0)\n",
    "\n",
    "            error1 = calculate_reprojection_error(point_3D, u1[0:2], self.K, view1.R, view1.t)\n",
    "            reprojection_error1.append(error1)\n",
    "            error2 = calculate_reprojection_error(point_3D, u2[0:2], self.K, view2.R, view2.t)\n",
    "            reprojection_error2.append(error2)\n",
    "\n",
    "            # updates point_map with the key (index of view, index of point in the view) and value point_counter\n",
    "            # multiple keys can have the same value because a 3D point is reconstructed using 2 points\n",
    "            self.point_map[(self.get_index_of_view(view1), match_object.inliers1[i])] = self.point_counter\n",
    "            self.point_map[(self.get_index_of_view(view2), match_object.inliers2[i])] = self.point_counter\n",
    "            self.point_counter += 1\n",
    "\n",
    "        return reprojection_error1, reprojection_error2\n",
    "\n",
    "    def compute_pose_PNP(self, view):\n",
    "        \"\"\"Computes pose of new view using perspective n-point\"\"\"\n",
    "\n",
    "        if view.feature_type in ['sift', 'surf']:\n",
    "            matcher = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False)\n",
    "        else:\n",
    "            matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=False)\n",
    "\n",
    "        # collects all the descriptors of the reconstructed views\n",
    "        old_descriptors = []\n",
    "        for old_view in self.done:\n",
    "            old_descriptors.append(old_view.descriptors)\n",
    "\n",
    "        # match old descriptors against the descriptors in the new view\n",
    "        matcher.add(old_descriptors)\n",
    "        matcher.train()\n",
    "        matches = matcher.match(queryDescriptors=view.descriptors)\n",
    "        points_3D, points_2D = np.zeros((0, 3)), np.zeros((0, 2))\n",
    "\n",
    "        # build corresponding array of 2D points and 3D points\n",
    "        for match in matches:\n",
    "            old_image_idx, new_image_kp_idx, old_image_kp_idx = match.imgIdx, match.queryIdx, match.trainIdx\n",
    "\n",
    "            if (old_image_idx, old_image_kp_idx) in self.point_map:\n",
    "\n",
    "                # obtain the 2D point from match\n",
    "                point_2D = np.array(view.keypoints[new_image_kp_idx].pt).T.reshape((1, 2))\n",
    "                points_2D = np.concatenate((points_2D, point_2D), axis=0)\n",
    "\n",
    "                # obtain the 3D point from the point_map\n",
    "                point_3D = self.points_3D[self.point_map[(old_image_idx, old_image_kp_idx)], :].T.reshape((1, 3))\n",
    "                points_3D = np.concatenate((points_3D, point_3D), axis=0)\n",
    "\n",
    "        # compute new pose using solvePnPRansac\n",
    "        _, R, t, _ = cv2.solvePnPRansac(points_3D[:, np.newaxis], points_2D[:, np.newaxis], self.K, None,\n",
    "                                        confidence=0.99, reprojectionError=8.0, flags=cv2.SOLVEPNP_DLS)\n",
    "        R, _ = cv2.Rodrigues(R)\n",
    "        return R, t\n",
    "\n",
    "    def plot_points(self):\n",
    "        \"\"\"Saves the reconstructed 3D points to ply files using Open3D\"\"\"\n",
    "\n",
    "        number = len(self.done)\n",
    "        filename = os.path.join(self.results_path, str(number) + '_images.ply')\n",
    "        pcd = o3d.geometry.PointCloud()\n",
    "        pcd.points = o3d.utility.Vector3dVector(self.points_3D)\n",
    "        o3d.io.write_point_cloud(filename, pcd)\n",
    "\n",
    "    def reconstruct(self):\n",
    "        \"\"\"Starts the main reconstruction loop for a given set of views and matches\"\"\"\n",
    "\n",
    "        # compute baseline pose\n",
    "        baseline_view1, baseline_view2 = self.views[0], self.views[1]\n",
    "        logging.info(\"Computing baseline pose and reconstructing points\")\n",
    "        self.compute_pose(view1=baseline_view1, view2=baseline_view2, is_baseline=True)\n",
    "        logging.info(\"Mean reprojection error for 1 image is %f\", self.errors[0])\n",
    "        logging.info(\"Mean reprojection error for 2 images is %f\", self.errors[1])\n",
    "        self.plot_points()\n",
    "        logging.info(\"Points plotted for %d views\", len(self.done))\n",
    "\n",
    "        for i in range(2, len(self.views)):\n",
    "\n",
    "            logging.info(\"Computing pose and reconstructing points for view %d\", i+1)\n",
    "            self.compute_pose(view1=self.views[i])\n",
    "            logging.info(\"Mean reprojection error for %d images is %f\", i+1, self.errors[i])\n",
    "            self.plot_points()\n",
    "            logging.info(\"Points plotted for %d views\", i+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfm = SFM(views, matches, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Computing baseline pose and reconstructing points\n",
      "INFO:root:Computed essential matrix\n",
      "INFO:root:Choosing correct pose out of 4 solutions\n",
      "INFO:root:Mean reprojection error for 1 image is 282.873410\n",
      "INFO:root:Mean reprojection error for 2 images is 358.592195\n",
      "INFO:root:Points plotted for 2 views\n",
      "INFO:root:Computing pose and reconstructing points for view 3\n",
      "INFO:root:Mean reprojection error for 3 images is 137.426099\n",
      "INFO:root:Points plotted for 3 views\n"
     ]
    }
   ],
   "source": [
    "sfm.reconstruct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfm.plot_points()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud = o3d.read_point_cloud(\"images/box_simple/points/2_images.ply\") # Read the point cloud\n",
    "o3d.draw_geometries([cloud])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "004e50a873f8cdd0114427b4411243458ccf09fbacd36406badfb38e87014507"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('reconstruction': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
